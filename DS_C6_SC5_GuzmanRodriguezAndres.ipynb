{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Qc_-xZy7dLzj"
      },
      "source": [
        "# Reto: Analítica de texto aplicada al estudio de sentimientos para la toma de decisiones\n",
        "\n",
        "\n",
        "**Objetivo:**\n",
        "\n",
        "- Construir un corpus utilizando las herramientas que has practicado a lo largo del módulo y realizar las siguientes actividades: calcular las frecuencias de longitudes de texto, frecuencias de palabras más comunes y extensión de vectores de stopwords.\n",
        "\n",
        "- Realizar las operaciones de procesamiento básico de textos: tokenizar, aplicar stemming, remover stopwords.\n",
        "- Crear gráficas para exploración de textos: histogramas, resumen de sentimientos, t-SNE o WordClouds.\n",
        "\n",
        "- Implementar y aplicar el análisis de sentimientos a los textos que se han recopilado en el corpus\n",
        "\n",
        "## Instrucciones\n",
        "## 1. Elige uno de los *datasets* para trabajar: En este caso se eligió el dataset de datos financieros. Cuyo archivo es **FinancialTweets.zip**.\n",
        "\n",
        "## 2. Generar un archivo para el reto, cuya estructura esté basada en los análisis solicitados.\n",
        "\n",
        "## 3. Del archivo descargado, guarda todos sus registros en un DataFrame."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LYGz_ZCnw86Y"
      },
      "outputs": [],
      "source": [
        "# Montando google drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ynQh1JouqvJ9"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "print(os.listdir('/content/drive/MyDrive/Colab'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "k952PozSerU7"
      },
      "outputs": [],
      "source": [
        "# Guardando registros en un dataframe\n",
        "import pandas as pd\n",
        "corpus = pd.read_csv('/content/drive/MyDrive/Colab/stockerbot-export.csv',\n",
        "                     on_bad_lines='skip')\n",
        "corpus.head(10)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TBz6_1abjWWq"
      },
      "outputs": [],
      "source": [
        "# Eliminando columnas que no se utilizarán en el análisis\n",
        "corpus = corpus.drop(columns={'id','timestamp','url'})\n",
        "corpus.head(10)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NmJAd8sxiqGF"
      },
      "source": [
        "## 4. Corre la preparación y creación de un corpus: cálculo de frecuencias de longitudes de texto, frecuencias de palabras más comunes, extensión de vectores de stopwords.\n",
        "\n",
        "## 5. Realiza las operaciones de procesamiento básico: tokenizar, aplicar stemming, remover stopwords"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AjlY5naskQKn"
      },
      "outputs": [],
      "source": [
        "# Importando bibliotecas\n",
        "import regex as re\n",
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "from collections import Counter\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from wordcloud import WordCloud\n",
        "nltk.download('punkt')\n",
        "nltk.download('wordnet')\n",
        "nltk.download('stopwords')\n",
        "stopwords_en = set(stopwords.words('english'))\n",
        "stopwords_extra = {'inc','ltd','llc','corp'}\n",
        "stopwords_all = stopwords_en.union(stopwords_extra)\n",
        "\n",
        "# Limpiar texto de URL, de RT y de entidades HTML\n",
        "def limpiar_texto(texto):\n",
        "    texto = texto.lower()\n",
        "    texto = re.sub(r'https\\S+|www\\S+', \"\",texto)\n",
        "    texto = re.sub(r'\\brt\\b', '',texto)\n",
        "    texto = re.sub(r'&\\w+;', '',texto)\n",
        "    texto = re.sub(r'[^a-z\\s]', '',texto)\n",
        "    return texto\n",
        "\n",
        "# Función para tokenizar texto\n",
        "def tokenize(texto):\n",
        "    return texto.split()\n",
        "\n",
        "# Función para quitar stopwords y palabras cortas\n",
        "def quita_stopwords(tokens, min_len = 3 ):\n",
        "    return [t for t in tokens if t not in stopwords_all and len(t) >=min_len]\n",
        "\n",
        "# Función para preprocesar texto\n",
        "def preprocesa_texto(texto):\n",
        "    tokens = limpiar_texto(texto)\n",
        "    tokens = tokenize(tokens)\n",
        "    tokens = quita_stopwords(tokens)\n",
        "    return tokens"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wBAPCc5ui3pT"
      },
      "outputs": [],
      "source": [
        "# Longitud\n",
        "corpus['review_len'] = corpus['text'].astype(str).apply(len)\n",
        "corpus['review_wc'] = corpus['text'].apply(lambda x: len(str(x).split()))\n",
        "\n",
        "# Tokenizar\n",
        "corpus['tokens'] = corpus['text'].astype(str).apply(\n",
        "    preprocesa_texto\n",
        ")\n",
        "corpus['tokens_wc'] = corpus['tokens'].apply(len)\n",
        "corpus.head(10)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5_UoFVglnA7k"
      },
      "source": [
        "## 6. Crea gráficas para exploración de textos: histogramas, resumen de sentimientos, t-SNE o WordClouds."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bVxxnmMOr7sW"
      },
      "outputs": [],
      "source": [
        "# Preparación para los gráficas\n",
        "tokens = [tok for tokens in corpus['tokens'] for tok in tokens]\n",
        "\n",
        "# Función palabras más comunes\n",
        "'''\n",
        "La función filtra las palabras más comunes de un corpus.\n",
        "'''\n",
        "def palabras_comunes(lista_tokens, top=25):\n",
        "    counter = Counter(lista_tokens)\n",
        "    mas_comunes = counter.most_common(top)\n",
        "    palabras, frecs = zip(*mas_comunes)\n",
        "    sns.barplot(x=frecs,y=palabras,palette='muted')\n",
        "    plt.title('Palabras más comunes')\n",
        "    plt.savefig('/content/drive/MyDrive/Colab/imagenes/mas_comunes.png')\n",
        "    plt.show()\n",
        "\n",
        "# Función nube de palabras\n",
        "'''\n",
        "Esta función genera una nube de palabras a partir de un corpus\n",
        "'''\n",
        "def  nube_palabras(corpus,stopwords,color):\n",
        "    stopwords = set(stopwords_all)\n",
        "    wordcloud = WordCloud(\n",
        "    background_color = color,\n",
        "    stopwords = stopwords,\n",
        "    max_words = 100,\n",
        "    max_font_size = 45,\n",
        "    min_font_size = 3,\n",
        "    random_state = 42)\n",
        "\n",
        "    wordcloud = wordcloud.generate(str(corpus))\n",
        "    fig = plt.figure(1, figsize=(12, 12))\n",
        "    plt.imshow(wordcloud)\n",
        "    plt.savefig('/content/drive/MyDrive/Colab/imagenes/nube_palabras.png')\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QvEWvmLgnEBS"
      },
      "outputs": [],
      "source": [
        "# Palabras más comunes\n",
        "palabras_comunes(tokens)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Gráfica de las 25 palabras más comúnes:\n",
        "\n",
        "![Palabras frecuentes](images/mas_comunes.png)"
      ],
      "metadata": {
        "id": "3sSh45SCpWVI"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "en8pI8MHvo_M"
      },
      "outputs": [],
      "source": [
        "# Nube de palabras\n",
        "nube_palabras(corpus,stopwords_all,'white')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Gráfica de la nube de palabras:\n",
        "\n",
        "![Nubes de palabras](images/nube_palabras.png)"
      ],
      "metadata": {
        "id": "JVU1l34msjcd"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2eq5-n-awDlf"
      },
      "outputs": [],
      "source": [
        "# Longitud de palabras\n",
        "'''Se omitirán los textos con más de 100 palabras'''\n",
        "sns.histplot(corpus[corpus['review_wc']<100]['review_wc'],\n",
        "             bins=30,\n",
        "             kde=False,\n",
        "             color='blue')\n",
        "plt.title('Distribución de la longitud de palabras')\n",
        "plt.xlabel('Número de palabras por texto')\n",
        "plt.ylabel('Frecuencia')\n",
        "plt.savefig('/content/drive/MyDrive/Colab/imagenes/longitud_palabras.png')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Longitud de las palabras en los tweets:\n",
        "\n",
        "![Longitud de las palabras](images/longitud_palabras.png)"
      ],
      "metadata": {
        "id": "r1vnBNHLsu3G"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YSLFLB0zwOrO"
      },
      "outputs": [],
      "source": [
        "# Longitud de tokens\n",
        "sns.histplot(corpus[corpus['tokens_wc']<30]['tokens_wc'],\n",
        "             bins=30,\n",
        "             kde=False,\n",
        "             color='green')\n",
        "plt.title('Distribución de la longitud de palabras')\n",
        "plt.xlabel('Número de tokens por texto')\n",
        "plt.ylabel('Frecuencia')\n",
        "plt.savefig('/content/drive/MyDrive/Colab/imagenes/longitud_tokens.png')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Longitud de los tokens:\n",
        "![Tokens](images/longitud_tokens.png)"
      ],
      "metadata": {
        "id": "kbmB5igHs9Ym"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oI_OiwKGx9p8"
      },
      "outputs": [],
      "source": [
        "!pip install pysentimiento"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sDOWvFHqxxrE"
      },
      "outputs": [],
      "source": [
        "# Análisis de sentimiento\n",
        "from pysentimiento import create_analyzer\n",
        "analyzer = create_analyzer(task=\"sentiment\", lang=\"en\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rq-V_KF7yYJI"
      },
      "outputs": [],
      "source": [
        "# Desactivar wandb\n",
        "import os\n",
        "os.environ['WANDB_DISABLED'] = 'true'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Kkkb5ru-zdVH"
      },
      "outputs": [],
      "source": [
        "# Análisis de sentimientos\n",
        "corpus['texto_limpio'] = corpus['tokens'].apply(lambda x: ' '.join(x))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eanf2jGpzpGF"
      },
      "outputs": [],
      "source": [
        "sentimiento = [analyzer.predict(t) for t in corpus['texto_limpio']]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ij58lClb1T8G"
      },
      "outputs": [],
      "source": [
        "corpus_copia = corpus.copy()\n",
        "sentimientos = []\n",
        "for probabilildad in sentimiento:\n",
        "    sentimientos.append(probabilildad.output)\n",
        "probabilidades = {'sentimiento':sentimientos}\n",
        "probabilidades = pd.DataFrame.from_dict(probabilidades)\n",
        "corpus_copia = pd.concat(\n",
        "    [corpus_copia,\n",
        "    probabilidades.reindex(corpus_copia.index)],\n",
        "    axis=1\n",
        ")\n",
        "corpus_copia.to_csv('corpus_sentimiento.csv',sep='\\t')\n",
        "corpus_copia['sentimiento'].value_counts().plot(\n",
        "    kind='bar',\n",
        "    color = ['#BB0000', '#0000BB', 'green'],\n",
        "    title='Financial Tweets Sentiment Analysis'\n",
        ")\n",
        "plt.savefig('/content/drive/MyDrive/Colab/imagenes/sentimientos.png')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Sentimientos en los tweets:\n",
        "\n",
        "![Sentimientos](images/sentimientos.png)"
      ],
      "metadata": {
        "id": "NCUqMWa8tF5f"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "64Ew8k-s5jfA"
      },
      "outputs": [],
      "source": [
        "# Sentimienetos por empresa\n",
        "top_empresas = corpus_copia['company_names'].value_counts().nlargest(20).index\n",
        "sns.countplot(\n",
        "    y='company_names',\n",
        "    hue='sentimiento',\n",
        "    data=corpus_copia[corpus_copia['company_names'].isin(top_empresas)],\n",
        "    palette='coolwarm')\n",
        "plt.title(\"Sentimiento por empresa\")\n",
        "plt.savefig('/content/drive/MyDrive/Colab/imagenes/sentimiento_empresas.png')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Sentimientos por empresa:\n",
        "\n",
        "![Palabras frecuentes](images/sentimiento_empresas.png)"
      ],
      "metadata": {
        "id": "D800JgX8tMVo"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4Th6vNCwyyfY"
      },
      "source": [
        "## 7. Agrega una interpretación de resultados obtenidos del análisis realizado.\n",
        "\n",
        "### Palabras más frecuentes\n",
        "A partir del análisis de los tweets financieros, las palabras más utilizadas son \"earnings, \"stocks\", \"price\", \"analysts\", \"eps\", etc. Estas se relacionan principamente en los resultados financieros de las empresas, así como el precio de las acciones y la participación de los analistas en la interpretación de estos resultados.\n",
        "\n",
        "Así mimso con los términos *earnings*  y *EPS (earnings per share)* indica que hay un gran interés en los reportes trimestrales.\n",
        "\n",
        "### Nube de palabras\n",
        "La nube de palabras revela los términos más frecuentes dentro del corpus como *BTC, price, True, False, American y optimistic*. Estos términos reflejan un enfoque en el ámbito financiero y criptográfico, donde se discuten temas con el valor de los activos, veracidad de la información y expectativas del mercado. Así mismo, la presencia de nombres propios, como Barry Silbert, y de empresas sugiere que gran parte del discurso se vincula con actores relevantes del sector.\n",
        "\n",
        "###  Distribución de la longitud de las palabras\n",
        "\n",
        "La distribución de la longitud de las palabras muestra que la mayoría de los textos son cortos, entre 10 y 25 palabras por tweet. Esto es consistente con la naturaleza de la discusión financiera en redes sociales como Twitter, donde los usuarios comparten noticias, opiniones rápidas, etc.\n",
        "\n",
        "### Análisis de Sentimientos\n",
        "En cuanto al análisis de sentimientos, se identificó que predomina el sentimiento neutro, seguido por el positivo y finalmente el negativo. Este resultado es coherente con el tipo de términos encontrados, ya que lo mayoría de tweets tiene un carácter descriptivo.\n",
        "Por lo tanto, el análisis revela que los tweets tienen a mantener un tono objetivo, lo que refuerza la percepción de que estas publicaciones son utilizadas para difusión y análisis especializado.\n",
        "\n",
        "Por otra parte, en el análisis de sentimiento por empresa, predonima igualmente el sentimiento neutro, lo que coincide con el carácter informativo y objetivo de los tweets. El sentimiento positivo ocupa el segundo lugar en la mayor parte de las empresas, a excepción de Netflix.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "G3Dxt2Gvkwg6"
      },
      "outputs": [],
      "source": [
        "import nbformat\n",
        "\n",
        "notebook_path = \"/content/drive/MyDrive/DS_C6_SC5_GuzmanRodriguezAndres.ipynb\"\n",
        "\n",
        "# Cargar notebook\n",
        "with open(notebook_path, \"r\", encoding=\"utf-8\") as f:\n",
        "    nb = nbformat.read(f, as_version=4)\n",
        "\n",
        "# Limpiar solo metadata.widgets corruptos\n",
        "for cell in nb.cells:\n",
        "    if \"metadata\" in cell and \"widgets\" in cell.metadata:\n",
        "        del cell.metadata[\"widgets\"]\n",
        "\n",
        "# Guardar notebook limpio\n",
        "with open(notebook_path, \"w\", encoding=\"utf-8\") as f:\n",
        "    nbformat.write(nb, f)\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": [],
      "authorship_tag": "ABX9TyPk+k5JZfZkre0ogkG6ZsDR"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}